{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0, 0, 1],\n",
    "             [0, 1, 1],\n",
    "             [1, 0, 1],\n",
    "             [1, 1, 1]])\n",
    "\n",
    "y = np.array([[0], [1], [1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n [0 1 1]\n [1 0 1]\n [1 1 1]]\n[[0]\n [1]\n [1]\n [0]]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "\n",
    "num_epochs = 100000\n",
    "\n",
    "\n",
    "# 5 neurons in the hidden layer\n",
    "syn0 = 2 * np.random.random((3, 5)) - 1\n",
    "syn1 = 2 * np.random.random((5, 1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.80554907 -0.48184687 -0.16124009 -0.79601376  0.93315435]\n [ 0.60482338  0.40575121  0.50729765 -0.35305451  0.22876282]\n [-0.46908305  0.56796475 -0.96940412 -0.92742003  0.01117627]]\n"
     ]
    }
   ],
   "source": [
    "print(syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01719185]\n [-0.45442365]\n [-0.79347534]\n [-0.39750967]\n [ 0.03009025]]\n"
     ]
    }
   ],
   "source": [
    "print(syn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, deriv = False):\n",
    "    if deriv:\n",
    "        return x * (1 - x)\n",
    "        \n",
    "    x = 1 / (1 + np.exp(-x))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(5)\n",
    "sigmoid(5, deriv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Function\n",
    "def train(x, y, syn0, syn1, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        l0 = x\n",
    "        l1 = sigmoid(np.dot(l0, syn0))\n",
    "        l2 = sigmoid(np.dot(l1, syn1))\n",
    "        \n",
    "        #  Error at the output layer\n",
    "        l2_error = y - l2\n",
    "        \n",
    "        # Derivative of the error for Gradient Descent\n",
    "        l2_derivative = l2_error * sigmoid(l2, deriv=True)\n",
    "        \n",
    "        # Contribution of l2 to l1\n",
    "        l1_error = l2_derivative.dot(syn1.T)\n",
    "        \n",
    "        if epoch % 1000 == 0:\n",
    "            print(\" Training .....  \\t Error : {0}\".format(np.mean(abs(l2_error))))\n",
    "        \n",
    "        # Derivative for gradient descent \n",
    "        l1_derivative = l1_error * sigmoid(l1, deriv=True)\n",
    "        \n",
    "        # Update the weights \n",
    "        syn1 += np.dot(l1.T, l2_derivative)\n",
    "        syn0 += np.dot(l0.T, l1_derivative)\n",
    "    print(\"Error: {0}\".format(l2_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training error is 0.00119975272603\n The training error is 0.00119818947655\n The training error is 0.00119663218456\n The training error is 0.00119508081255\n The training error is 0.00119353532334\n The training error is 0.00119199568008\n The training error is 0.00119046184621\n The training error is 0.00118893378553\n The training error is 0.00118741146214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training error is 0.00118589484043\n The training error is 0.00118438388512\n The training error is 0.00118287856124\n The training error is 0.00118137883409\n The training error is 0.0011798846693\n The training error is 0.00117839603278\n The training error is 0.00117691289073\n The training error is 0.00117543520964\n The training error is 0.00117396295627\n The training error is 0.0011724960977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training error is 0.00117103460125\n The training error is 0.00116957843452\n The training error is 0.00116812756541\n The training error is 0.00116668196206\n The training error is 0.00116524159289\n The training error is 0.00116380642659\n The training error is 0.00116237643209\n The training error is 0.00116095157859\n The training error is 0.00115953183556\n The training error is 0.0011581171727\n The training error is 0.00115670755997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training error is 0.00115530296758\n The training error is 0.00115390336597\n The training error is 0.00115250872584\n The training error is 0.00115111901813\n The training error is 0.001149734214\n The training error is 0.00114835428486\n The training error is 0.00114697920234\n The training error is 0.00114560893832\n The training error is 0.00114424346488\n The training error is 0.00114288275435\n The training error is 0.00114152677926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training error is 0.00114017551239\n The training error is 0.0011388289267\n The training error is 0.00113748699541\n The training error is 0.00113614969191\n The training error is 0.00113481698983\n The training error is 0.00113348886301\n The training error is 0.00113216528547\n The training error is 0.00113084623147\n The training error is 0.00112953167545\n The training error is 0.00112822159206\n The training error is 0.00112691595614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training error is 0.00112561474274\n The training error is 0.0011243179271\n The training error is 0.00112302548466\n The training error is 0.00112173739102\n The training error is 0.00112045362202\n The training error is 0.00111917415363\n The training error is 0.00111789896207\n The training error is 0.00111662802368\n The training error is 0.00111536131502\n The training error is 0.00111409881283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training error is 0.00111284049401\n The training error is 0.00111158633565\n The training error is 0.001110336315\n The training error is 0.00110909040951\n The training error is 0.00110784859678\n The training error is 0.00110661085458\n The training error is 0.00110537716086\n The training error is 0.00110414749372\n The training error is 0.00110292183144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training error is 0.00110170015246\n The training error is 0.00110048243538\n The training error is 0.00109926865896\n The training error is 0.00109805880211\n The training error is 0.00109685284391\n The training error is 0.00109565076359\n The training error is 0.00109445254055\n The training error is 0.0010932581543\n The training error is 0.00109206758455\n The training error is 0.00109088081113\n The training error is 0.00108969781403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training error is 0.00108851857339\n The training error is 0.00108734306947\n The training error is 0.00108617128272\n The training error is 0.00108500319368\n The training error is 0.00108383878308\n The training error is 0.00108267803177\n The training error is 0.00108152092071\n The training error is 0.00108036743106\n The training error is 0.00107921754405\n The training error is 0.0010780712411\n The training error is 0.00107692850373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training error is 0.0010757893136\n The training error is 0.00107465365251\n The training error is 0.00107352150238\n The training error is 0.00107239284527\n The training error is 0.00107126766335\n The training error is 0.00107014593894\n The training error is 0.00106902765447\n"
     ]
    }
   ],
   "source": [
    "train(x, y, syn0, syn1, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}